Chapter 1
Introduction
1.1
Motivation
Question Generation (QG) is the task of automatically generating human-like questions
from some input sources like a passage, answer, paragraph, context or a statement (Zhang
et al., 2021). As in the field of Artificial Intelligence (AI), QG is considered an important
topic, and is gaining focus in both the academic research and industry fields (Zhang et al.,
2021). In recent years, QG has been a topic of extensive research. But most of the research
is based on the generation of a single question from a single paragraph where the answer to
the question depends on a small amount of reasoning (Emerson and Chali, 2023a). From
the SQuAD dataset (Rajpurkar et al., 2016), Min et al. (2018) found that approximately
90% of the questions can be generated from a single sentence within the input paragraph
(Emerson and Chali, 2023a).
The basic structure of a question generation task can be defined as: input - a sequence of
text, and output - a grammatically correct question which is relevant to the input. To gen-
erate questions, there are two basic approaches available. One is the rule-based approach
and the other is the neural network-based approach. In a rule-based approach, predefined
linguistic rules, templates, patterns, and grammatical structures are utilized to generate ac-
curate questions. In the neural network-based approach, the question is predicted on the
basis of the neural network architectures. Some neural network architectures which can
be used for generating questions are the sequence-to-sequence (Seq2seq) model, the graph
neural network (GNN), transformers and large language models (LLMs).
1

1.1. MOTIVATION
In QG, different types of questions can be generated by following one specific process.
Some specific question generation processes are answer-aware question generation, answer-
unaware question generation, paragraph-based question generation, single-hop question
generation, multi-hop question generation, single reference question generation, and multi-
ple reference question generation. In single-hop question generation, the generated question
is dependent only on one passage, and the question is generated using only one sentence
of the passage or some relevant information of the passage. It requires simple reasoning to
answer the question in the paragraph. Multi-hop questions generation is more complex as it
requires multiple reasoning in multiple paragraphs (or even different documents) to answer
the question (Lin et al., 2024). Simply, the answer of a multi-hop question is dependent on
multiple (two or more) paragraphs. If an individual wants to generate multi-hop question,
they must read all input passages, understand the facts from them, understand the relation-
ship between the facts, connect them, and generate a multi-hop meaningful question from
the connected information.
The interest of research on multi-hop question generation is increasing as QG can be applied
in different areas like the educational system, medical and clinical tools, chatbot compo-
nents, and also other Natural Language Generation (NLG) tasks like question answering
systems. Some real world application of multi-hop question generation system are given
below.
• Search Engine Query Generation
As human beings usually struggles to generate actual questions during the time of
asking questions in a search engine, a multi-hop question generation model can be
applied to express the mind of the person by generating appropriate questions which
can lead to deep explanation of a specific topic.
• Educational System
To know the accurate answer, it is required to ask the accurate questions. Multi-hop
question generation can be applied in educational systems like enhancing learning ex-
2

1.1. MOTIVATION
perience for students by generating quiz, test, and assignment questions. To enhance
interactive learning systems, multi-hop questions can be effective as they require mul-
tiple steps to answer.
• Natural Language Processing (NLP) Tasks
Multi-hop question generation system can be used in different NLP tasks like chatbot
design and question answering (QA) systems. When communicating with a chatbot,
a multi-hop question generation model can be applied to express complex followup
questions. To build up a question answering system, it is required to have a huge
amount of labeled question-answer pairs for training when multi-hop reasoning is
essential. As manual generation of a dataset is complex and time consuming, the
generated questions by the multi-hop question generation system can be added to the
dataset and can be deployed during training to build an effective QA system.
• Medical Applications
A multi-hop question generation model can be applied in medical and clinical tools
like patient history generation, virtual assistance, and appointment scheduling.
• Security and Privacy
By generating stepwise diagnostic questions, multi-hop question generation system
can help identifying threats and vulnerabilities in a network.
In our work, a Knowledge Graph (KG) is generated from input text, while a Graph Attention
Network (GAT) is leveraged for graph embedding. To the best of our knowledge, this is the
first work where a knowledge graph is combined with an LLM to generate a better result
by handling graph-structured data.
The main motivation of this research is to find a strategy to generate complex multi-hop
questions that improves upon previous works. Sequence-to-sequence-based transformer
models are already capable of generating simple questions where only one single paragraph
is required to provide a logical solution to the question. However, the issue arises as to
3

1.2. CONTRIBUTIONS
whether those models are capable of generating complex questions where we need multiple
paragraphs to provide a complete solution to the question. The main key factors in the
motivation for this thesis are given below.
• Complex Reasoning
A multi-hop question can easily be defined as a question in which multiple sources/-
paragraphs are required to answer them. The model should be capable of collecting
appropriate information from each paragraph, after which the model should be ca-
pable of merging the collected information to generate questions so that complex
reasoning of different paragraphs should be ensured by reasoning path.
• Ensuring Commonsense Reasoning and Mitigating Hallucination
One of the major issues and drawbacks of large language models is hallucination. It
can reduce the performance of the model. Ensuring commonsense reasoning is an
effective way to mitigate hallucination. One of the motivations of this research is to
ensure commonsense reasoning of the model so that it does not hallucinate.
• Supporting Information Retrieval System
The generated questions from the model can help in information retrieval, question-
answering systems, text summarization, and chatbot design.
1.2
Contributions
The thesis has great impact on the multi-hop question generation system by creating
key contributions on the following aspects.
1. Combining Knowledge Graph with LLMs
Usually, the input text is tokenized and converted into embeddings as the input in
LLMs. However, in this research, the concatenation of KG embedding with input
text embedding is done, which is utilized as input for the LLMs. To the best of our
4

1.3. THESIS ORGANIZATION
knowledge, this model offers the unique contribution for first leveraging a KG as
input in LLMs.
2. Integrating SBERT and GAT
In this research, a sentence transformer (SBERT1) and a GAT are integrated. For
input text embedding generation SBERT is used, and for KG embedding generation
GAT is used. This approach has enriched the performance of LLMs by handling
structured graph data with input text which has made a great contribution in the field
of multi-hop question generation.
3. Triplet Dataset Contribution
For this research, we have proposed a triplet dataset that presents the knowledge
graph for each input text. This triplet dataset consists of entities and the predicates
between two entities. This dataset can be used in the further research of the multi-hop
question generation. Also the implementation of this research is made available as an
open-source resource which can be considered a contribution of encouraging further
research and development in multi-hop question generation.
4. Enhancement of Multi-hop Question Generation
After doing evaluations from the result of the experiments conducted on the Hot-
potQA 2 dataset, the evaluation has shown a notable increase in the quality of the
generated multi-hop questions and the metrics compared to the existing models.
1.3
Thesis Organization
The thesis is organized as follows.
- Chapter 2 provides the background details and fundamental concepts required
to understand the different methodologies and technologies used in the thesis.
1sbert.net.
2https://huggingface.co/datasets/hotpotqa/hotpot qa.
5

1.3. CONTRIBUTIONS
- Chapter 3 discusses the previously completed work and literature review of
question generation.
- Chapter 4 defines the problem definition and proposed methodology of multi-
hop question generation. This chapter explains the model architecture, its strength,
underlying algorithms, and an explanation of choosing the models.
- Chapter 5 presents the dataset used in this thesis, evaluation metrics, experi-
mental setup, model implementation, and experimental results.
- Chapter 6 provides the thesis conclusion and direction for further research on
the advancement of multi-hop question generation research.
6
