CS 4774 Machine Learning
Introduction to Learning Theory
Yangfeng Ji
Information and Language Processing Lab
Department of Computer Science
University of Virginia

--------------------------------------------------------------------------------
[End of Page 1]

Overview
1. A Toy Example
2. True Classification Error
3. Empirical Risk Minimization
4. Finite Hypothesis Classes
5. PAC Learning
6. Agnostic PAC Learning
1

--------------------------------------------------------------------------------
[End of Page 2]

Real-world Classification Problem
Image classification
14M images, 20K categories
2

--------------------------------------------------------------------------------
[End of Page 3]

Real-world Classification Problem (II)
Sentiment classification
192K businesses, 6.6M user reviews
3

--------------------------------------------------------------------------------
[End of Page 4]

Questions
Q1 What is the first example of machine learning applications that
you can think of?
Q2 What are the challenges of building machine learning models for
that application?
4

--------------------------------------------------------------------------------
[End of Page 5]

Objective
The objective of this lecture is
to talk about the essence of machine learning without getting
distracted by some real-world constraints.
5

--------------------------------------------------------------------------------
[End of Page 6]

A Toy Example

--------------------------------------------------------------------------------
[End of Page 7]

Question
Our very first machine learning example:
Based on the following observations, try to find out the shape/size of the area
where the positive examples come from, so we can make the best predictions
on future observations
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
7

--------------------------------------------------------------------------------
[End of Page 8]

Question
Our very first machine learning example:
Based on the following observations, try to find out the shape/size of the area
where the positive examples come from, so we can make the best predictions
on future observations
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
We have to make certain assumptions, otherwise there is no way to
answer this question.
7

--------------------------------------------------------------------------------
[End of Page 9]

Hypotheses
Given these data points, answer the following two questions:
1. Which shape is the underlying
distribution of red points?
â–¶A triangle
â–¶A rectangle
â–¶A circle
â–¶A shape that we (or
probably just me) cannot
describe
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
8

--------------------------------------------------------------------------------
[End of Page 10]

Hypotheses
Given these data points, answer the following two questions:
1. Which shape is the underlying
distribution of red points?
â–¶A triangle
â–¶A rectangle
â–¶A circle
â–¶A shape that we (or
probably just me) cannot
describe
2. What is the size of that shape?
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
8

--------------------------------------------------------------------------------
[End of Page 11]

Basic Concepts (I)
Domain set or input space X: the set of all possible examples
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
â–¶In this case, X = â„2
â–¶Each point ğ’™in X, ğ’™âˆˆX, is called one example or instance.
9

--------------------------------------------------------------------------------
[End of Page 12]

Basic Concepts (II)
Label set or output space Y: the set of all possible labels
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
â–¶In this case, Y âˆˆ{+, âˆ’}
â–¶In this course, we often restrict the label set to be a two-element
set, such as {+1, âˆ’1}
10

--------------------------------------------------------------------------------
[End of Page 13]

Basic Concept (III)
Training set ğ‘†: a finite sequence of pairs in XÃ— Y, represented as
{(ğ’™1, ğ‘¦1), (ğ’™2, ğ‘¦2), . . . , (ğ’™ğ‘š, ğ‘¦ğ‘š)} with size ğ‘š
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
11

--------------------------------------------------------------------------------
[End of Page 14]

Basic Concept: Hypothesis Space
â–¶Hypothesis class or hypothesis space H: a set of functions that
map instances to labels
â–¶Each element â„in this hypothesis class is called a hypothesis
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
Figure: Two hypotheses from the Circle class.
12

--------------------------------------------------------------------------------
[End of Page 15]

Basic Concept: Hypothesis Space (Cont.)
If we represent a hypothesis by its parameter value, then each
hypothesis corresponds one point in the hypothesis space.
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
Center ğ‘¥1
Center ğ‘¥2
radius
Figure: Visualizing the Circle hypothesis class.
13

--------------------------------------------------------------------------------
[End of Page 16]

Basic Concept: Machine Learners
â–¶A (machine) learner is an algorithm ğ´that can find an optimal
hypothesis from Hbased on the training set ğ‘†
â–¶This optimal hypothesis is represented as ğ´(ğ‘†)
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
Center ğ‘¥1
Center ğ‘¥2
radius
â–¶A hypothesis space His learnable if such an algorithm ğ´exists1
1A precise definition will be provided later in this lecture.
14

--------------------------------------------------------------------------------
[End of Page 17]

Why a Toy Problem?
With a toy problem, we can have the following conveniences that we
usually do not have with real-world problem,
â–¶Do not need data pre-processing
â–¶Do not need feature engineering
â–¶Make some unrealistic assumptions, e.g.,
â–¶Assume we know the underlying data distribution
â–¶Assume we know the optimal classifier given the data distribution
15

--------------------------------------------------------------------------------
[End of Page 18]

True Classification Error

--------------------------------------------------------------------------------
[End of Page 19]

Basic Concepts: Summary
â–¶Domain set X
â–¶Label set Y
â–¶Training data ğ‘†: the
observations
â–¶Hypothesis class H
â–¶rectangle class
â–¶A learner ğ´
â–¶an algorithm that finds an
optimal hypothesis
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
17

--------------------------------------------------------------------------------
[End of Page 20]

Data Generation Process
An idealized process to illustrate the relations among domain set X,
label set Y, and the training set ğ‘†
1. the probability distribution D over the domain set X
2. sample an instance ğ’™âˆˆXaccording to D
3. annotate it using the labeling function ğ‘“as ğ‘¦= ğ‘“(ğ’™)
âˆ’6
âˆ’4
âˆ’2
0
2
4
6
5 Â· 10âˆ’2
0.1
0.15
0.2
18

--------------------------------------------------------------------------------
[End of Page 21]

Example
Assume the data distribution D over the domain set Xis defined as
D :
ğ‘(ğ‘¥) = 1
2N(ğ‘¥; 2, 1)
|       {z       }
component 1
+ 1
2N(ğ‘¥; âˆ’2, 1)
|         {z         }
component 2
(1)
The specific data generation process: for each data point
19

--------------------------------------------------------------------------------
[End of Page 22]

Example
Assume the data distribution D over the domain set Xis defined as
D :
ğ‘(ğ‘¥) = 1
2N(ğ‘¥; 2, 1)
|       {z       }
component 1
+ 1
2N(ğ‘¥; âˆ’2, 1)
|         {z         }
component 2
(1)
The specific data generation process: for each data point
1. Randomly select one out of two Gaussian components with
probability 50%
19

--------------------------------------------------------------------------------
[End of Page 23]

Example
Assume the data distribution D over the domain set Xis defined as
D :
ğ‘(ğ‘¥) = 1
2N(ğ‘¥; 2, 1)
|       {z       }
component 1
+ 1
2N(ğ‘¥; âˆ’2, 1)
|         {z         }
component 2
(1)
The specific data generation process: for each data point
1. Randomly select one out of two Gaussian components with
probability 50%
2. Sample ğ‘¥from that Gaussian component
19

--------------------------------------------------------------------------------
[End of Page 24]

Example
Assume the data distribution D over the domain set Xis defined as
D :
ğ‘(ğ‘¥) = 1
2N(ğ‘¥; 2, 1)
|       {z       }
component 1
+ 1
2N(ğ‘¥; âˆ’2, 1)
|         {z         }
component 2
(1)
The specific data generation process: for each data point
1. Randomly select one out of two Gaussian components with
probability 50%
2. Sample ğ‘¥from that Gaussian component
3. Label ğ‘¥based on which component was selected at step 1
â–¶Component 1: positive
â–¶Component 2: negative
19

--------------------------------------------------------------------------------
[End of Page 25]

Example (Cont.)
Sampled data distribution
20

--------------------------------------------------------------------------------
[End of Page 26]

Example (Cont.)
Sampled data distribution
True distribution
âˆ’6
âˆ’4
âˆ’2
0
2
4
6
5 Â· 10âˆ’2
0.1
0.15
0.2
20

--------------------------------------------------------------------------------
[End of Page 27]

Example (Cont.)
Sampled data distribution
True distribution
âˆ’6
âˆ’4
âˆ’2
0
2
4
6
5 Â· 10âˆ’2
0.1
0.15
0.2
In this section, we will talk about how to measure the classification
error if we know the true data distribution.
20

--------------------------------------------------------------------------------
[End of Page 28]

Classification Error with True Data Distribution
The classification error will happen when the hypothesis â„does not
predict the correct label on a randomly generated instance ğ’™
âˆ’6
âˆ’4
âˆ’2
0
2
4
6
5 Â· 10âˆ’2
0.1
0.15
0.2
21

--------------------------------------------------------------------------------
[End of Page 29]

Example
Re-formulate the data generation process in probabilistic language
ğ‘(ğ‘¦= +1) = ğ‘(ğ‘¦= âˆ’1) = 1
2
ğ‘(ğ‘¥| ğ‘¦= +1) = N(ğ‘¥; 2, 1)
ğ‘(ğ‘¥| ğ‘¦= âˆ’1) = N(ğ‘¥; âˆ’2, 1)
(2)
âˆ’6
âˆ’4
âˆ’2
0
2
4
6
5 Â· 10âˆ’2
0.1
0.15
0.2
22

--------------------------------------------------------------------------------
[End of Page 30]

The Bayes Predictor
If â„is defined as
â„(ğ‘¥) =

+1
ğ‘(+1 | ğ‘¥) â‰¥ğ‘(âˆ’1 | ğ‘¥)
âˆ’1
otherwise
(3)
then what is the classification error?
âˆ’6
âˆ’4
âˆ’2
0
2
4
6
5 Â· 10âˆ’2
0.1
0.15
0.2
23

--------------------------------------------------------------------------------
[End of Page 31]

The Bayes Predictor
If â„is defined as
â„(ğ‘¥) =

+1
ğ‘(+1 | ğ‘¥) â‰¥ğ‘(âˆ’1 | ğ‘¥)
âˆ’1
otherwise
(3)
then what is the classification error?
âˆ’6
âˆ’4
âˆ’2
0
2
4
6
5 Â· 10âˆ’2
0.1
0.15
0.2
The Bayes predictor: the best predictor if we know the true data
distribution (more detail will be discussed later)
23

--------------------------------------------------------------------------------
[End of Page 32]

True Error
â–¶The true error of a hypothesis â„as the probability that it does not
predict the correct label on a randomly generated instance ğ’™
following distribution D
â–¶Definition
ğ¿D, ğ‘“(â„) = â„™ğ’™âˆ¼D[â„(ğ’™) â‰ ğ‘“(ğ’™)]
(4)
â–¶ğ’™âˆ¼D: an instance generated following the distribution D
â–¶â„(ğ’™) â‰ ğ‘“(ğ’™): prediction from hypothesis â„does not match the
labeling function output
â–¶ğ¿D, ğ‘“(â„): the error of â„is measured with respect to D and ğ‘“
24

--------------------------------------------------------------------------------
[End of Page 33]

Other Names
Definition:
ğ¿D, ğ‘“(â„) = â„™ğ’™âˆ¼D[â„(ğ’™) â‰ ğ‘“(ğ’™)]
(5)
Other names (used interchangably):
â–¶the generalization error
â–¶the true risk
25

--------------------------------------------------------------------------------
[End of Page 34]

Comments
Recall the definition of true risk with the data distribution D and the
labeling function ğ‘“
ğ¿D, ğ‘“(â„) = â„™ğ’™âˆ¼D[â„(ğ’™) â‰ ğ‘“(ğ’™)]
(6)
It is impossible to compute ğ¿D, ğ‘“(â„) in practice, since we do not know
â–¶the distribution of data generation D
â–¶the labeling function ğ‘“
Alternative option: Empirical Risk
26

--------------------------------------------------------------------------------
[End of Page 35]

Empirical Risk Minimization

--------------------------------------------------------------------------------
[End of Page 36]

Empirical Risk
The definition of the empirical risk (or, empirical error, training
error):
ğ¿ğ‘†(â„) = |{ğ‘–âˆˆ[ğ‘š] : â„(ğ’™ğ‘–) â‰ ğ‘¦ğ‘–}|
ğ‘š
(7)
Notations
â–¶[ğ‘š] = {1, 2, . . . , ğ‘š} where ğ‘šis the total number of instances in ğ‘†
â–¶{ğ‘–âˆˆ[ğ‘š] : â„(ğ’™ğ‘–) â‰ ğ‘¦ğ‘–}: the set of instances that â„predicts wrong
â–¶|{ğ‘–âˆˆ[ğ‘š] : â„(ğ’™ğ‘–) â‰ ğ‘¦ğ‘–}|: the size of the set
â–¶ğ¿ğ‘†(â„) defines with respect to the set ğ‘†
28

--------------------------------------------------------------------------------
[End of Page 37]

Example
The empirical risk of a hypothesis â„is defined on the training set ğ‘†:
ğ¿ğ‘†(â„) = |{ğ‘–âˆˆ[ğ‘š] : â„(ğ’™ğ‘–) â‰ ğ‘¦ğ‘–}|
ğ‘š
(8)
Figure: 1K examples generated with the previous process.
29

--------------------------------------------------------------------------------
[End of Page 38]

Empirical Risk Minimization: Definition
Empirical Risk Minimization (ERM): given the training set ğ‘†and the
hypothesis class H
â„âˆˆargmin
â„âˆˆH
ğ¿ğ‘†(â„)
(9)
â–¶argmin stands for the set of hypotheses in Hthat achieve the
minimum value of ğ¿ğ‘†(â„) over H
â–¶In general, there is always at least one hypothesis that makes
ğ¿ğ‘†(â„) = 0 with an unrealistically large H
30

--------------------------------------------------------------------------------
[End of Page 39]

Empirical Risk Minimization: Limitation
For example, with an unrealistically large hypothesis class H, we can
always minimize the empirical error and make it zero
â„ğ‘†(ğ’™) =

ğ‘¦ğ‘–
if (ğ’™= ğ’™ğ‘–) âˆ§(ğ’™ğ‘–âˆˆğ‘†)
unknown
otherwise
(10)
no matter how many instances in ğ‘†
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
31

--------------------------------------------------------------------------------
[End of Page 40]

Empirical Risk Minimization: Limitation
For example, with an unrealistically large hypothesis class H, we can
always minimize the empirical error and make it zero
â„ğ‘†(ğ’™) =

ğ‘¦ğ‘–
if (ğ’™= ğ’™ğ‘–) âˆ§(ğ’™ğ‘–âˆˆğ‘†)
unknown
otherwise
(10)
no matter how many instances in ğ‘†
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
31

--------------------------------------------------------------------------------
[End of Page 41]

Overfitting
Although this is just an extreme case, it illustrates an important
phenomenon, called overfitting
ğ‘¥1
ğ‘¥2
+
+
+
+
-
-
-
-
-
â–¶The performance on the training set is excellent; but on the whole
distribution was very poor
â–¶Continue our discussion on lecture 6: model selection and
validation
32

--------------------------------------------------------------------------------
[End of Page 42]

Inductive Bias
â€œA learner that makes no a priori assumptions regarding the identity of the
target concept2 has no rational basis for classifying any unseen instances.â€
[Mitchell, 1997, Page 42]
2labeling function, in the context of our discussion
33

--------------------------------------------------------------------------------
[End of Page 43]

Finite Hypothesis Classes

--------------------------------------------------------------------------------
[End of Page 44]

A Learning Problem
Assume we know the following information:
â–¶Domain set X = [0, 1]
â–¶Distribution D: the uniform distribution over X
â–¶Label set Y = {âˆ’1, +1}
â–¶Labeling function ğ‘“
ğ‘“(ğ‘¥) =

âˆ’1
0 â‰¤ğ‘¥< ğ‘
+1
ğ‘â‰¤ğ‘¥â‰¤1
(11)
with ğ‘is unknown
35

--------------------------------------------------------------------------------
[End of Page 45]

A Learning Problem
Assume we know the following information:
â–¶Domain set X = [0, 1]
â–¶Distribution D: the uniform distribution over X
â–¶Label set Y = {âˆ’1, +1}
â–¶Labeling function ğ‘“
ğ‘“(ğ‘¥) =

âˆ’1
0 â‰¤ğ‘¥< ğ‘
+1
ğ‘â‰¤ğ‘¥â‰¤1
(11)
with ğ‘is unknown
The learning problem is defined as
â–¶Given a set of observations ğ‘†= {(ğ‘¥1, ğ‘¦1), . . . , (ğ‘¥ğ‘š, ğ‘¦ğ‘š)}, is there a
learning algorithm that can find a good approximation of ğ‘?
35

--------------------------------------------------------------------------------
[End of Page 46]

A Training Set ğ‘†
Consider the following training sets, each of them contains eight data
points, can a learning algorithm find the dividing point?
Training set ğ‘†
[Code]
36

--------------------------------------------------------------------------------
[End of Page 47]

Finite Hypothesis Class
â–¶The finite hypothesis class of dividing points
Hğ‘“= {â„ğ‘–: ğ‘–âˆˆ[10]}
(12)
with each â„ğ‘–defined as
â„ğ‘–(ğ‘¥) =

âˆ’1
0 â‰¤ğ‘¥<
ğ‘–
10
+1
ğ‘–
10 â‰¤ğ‘¥â‰¤1
(13)
37

--------------------------------------------------------------------------------
[End of Page 48]

The Realizability Assumption
The Realizability Assumption:
There exists â„âˆ—âˆˆHsuch that ğ¿D, ğ‘“(â„âˆ—) = 0
[Shalev-Shwartz and Ben-David, 2014, Definition 2.1]
Comments
â–¶ğ¿D, ğ‘“indicates this is the true error
â–¶this assumption implies ğ¿ğ‘†(â„ğ‘†) = 0,
where ğ¿ğ‘ is the empirical risk based on the training set ğ‘†and â„ğ‘†is the
hypothesis found by minimizing the empirical risk based on ğ‘†
38

--------------------------------------------------------------------------------
[End of Page 49]

A Learning Algorithm
â–¶A learner: the brute force algorithm
â–¶try the hypotheses one by one and find the best
â–¶time complexity O(|Hğ‘“|)
â–¶better algorithms exist, such as binary search algorithm
39

--------------------------------------------------------------------------------
[End of Page 50]

Nonrepresentative Training Set
â–¶Consider the following training set (no negative example)3
â–¶Introduce ğ›¿âˆˆ(0, 1) to capture nonrepresentative cases. With
probability (1 âˆ’ğ›¿), we have representative cases
â–¶Loosely speaking, in the running example, at least ğ‘†has both
positive and negative instances
â–¶(1 âˆ’ğ›¿) is called confidence parameter
3Run the demo code about ten times, you may be able to see this happens once.
40

--------------------------------------------------------------------------------
[End of Page 51]

Nonperfect Predictors
Consider the following training instances
â–¶Follow the realizability assumption, there exists ğ¿ğ‘†(â„ğ‘†) = 0
â–¶But there is no guarantee that ğ¿(D, ğ‘“)(â„ğ‘†) = 0
â–¶Relax the constraint as
ğ¿(D, ğ‘“)(â„ğ‘†) â‰¤ğœ–
(14)
where ğœ–is called accuracy parameter
41

--------------------------------------------------------------------------------
[End of Page 52]

Sample Complexity
â–¶In the running example, we use ğ‘š= 8
â–¶Intuitively, if we increase the size of ğ‘†, we will have a better
chance to identify the labeling function ğ‘“. For example, when
ğ‘š= 691
42

--------------------------------------------------------------------------------
[End of Page 53]

Summary of the Issues
1. Nonrepresentative training Set
â–¶Missing critical information about the data distribution D
2. Nonperfect predictors
â–¶ğ¿ğ‘†(â„ğ‘†) = 0, but ğ¿D, ğ‘“(â„ğ‘†) â‰ 0
3. Mismatch of the hypothesis space
â–¶The realizability assumption is unrealistic for practical applications
The first two issues are considered in the PAC learning model, and
the last issue is considered in the agnostic PAC learning model.
43

--------------------------------------------------------------------------------
[End of Page 54]

PAC Learning

--------------------------------------------------------------------------------
[End of Page 55]

The Realization Assumption
Let keep this assumption in this section
There exists â„âˆ—âˆˆHsuch that ğ¿D, ğ‘“(â„âˆ—) = 0
Comments
â–¶ğ¿D, ğ‘“(â„âˆ—) is the true error
â–¶It implies, with probability 1, every ERM hypothesis ğ¿ğ‘†(â„ğ‘†) = 0
â–¶It is a strong assumption for theoretical analysis purpose. In
practice, we do not have a such guarantee
45

--------------------------------------------------------------------------------
[End of Page 56]

A Oversimplified Definition of PAC Learnability
A hypothesis class His PAC learnable if there exists a learning
algorithm with the following property:
â–¶for every distribution D over Xand
â–¶for every labeling function ğ‘“: X â†’{0, 1}
with enough training examples, the algorithm returns a hypothesis â„
such that with a large probability that
ğ¿D, ğ‘“(â„)
(15)
is arbitrarily small.
46

--------------------------------------------------------------------------------
[End of Page 57]

Distribution D over X
Consider the distribution over [0, 1]
â–¶Uniform distribution
47

--------------------------------------------------------------------------------
[End of Page 58]

Distribution D over X
Consider the distribution over [0, 1]
â–¶Uniform distribution
â–¶Beta distributions
ğ‘(ğ‘¥; ğ›¼, ğ›½) =
1
ğµ(ğ›¼, ğ›½) ğ‘¥ğ›¼âˆ’1(1 âˆ’ğ‘¥)ğ›½âˆ’1
(16)
â–¶Many other distributions
47

--------------------------------------------------------------------------------
[End of Page 59]

Distribution D over X
Consider the distribution over [0, 1]
â–¶Uniform distribution
â–¶Beta distributions
ğ‘(ğ‘¥; ğ›¼, ğ›½) =
1
ğµ(ğ›¼, ğ›½) ğ‘¥ğ›¼âˆ’1(1 âˆ’ğ‘¥)ğ›½âˆ’1
(16)
â–¶Many other distributions
We expect that, if there exists a learning algorithm ğ´, it should work
with all kinds of different distributions.
47

--------------------------------------------------------------------------------
[End of Page 60]

Labeling Function ğ‘“: X â†’{0, 1}
For the problem of finding the dividing point, the labeling function is
defined as
ğ‘“(ğ‘¥) =

âˆ’1
0 â‰¤ğ‘¥< ğ‘
+1
ğ‘â‰¤ğ‘¥â‰¤1
(17)
â–¶ğ‘can be any number here, as long as it follows the realization
assumption. In other words, the labeling function is in the
hypothesis space ğ‘“âˆˆH
â–¶We will discuss the scenario of ğ‘“âˆ‰Hin next section
48

--------------------------------------------------------------------------------
[End of Page 61]

A Simplified Definition of PAC Learnability
A hypothesis class His PAC learnable if there exists a learning
algorithm with the following property:
â–¶for every distribution D over X
â–¶for every labeling function ğ‘“: X â†’{0, 1}, and
â–¶for every ğœ–, ğ›¿âˆˆ(0, 1)
with enough training examples, the algorithm returns a hypothesis â„
such that, with probability of at least 1 âˆ’ğ›¿,
ğ¿D, ğ‘“(â„) â‰¤ğœ–
(18)
49

--------------------------------------------------------------------------------
[End of Page 62]

Accuracy Parameter ğœ–
The accuracy parameter ğœ–determines how far the output classifier
can be from the optimal one
A Simplified Definition
. . .
ğ¿D, ğ‘“(â„) â‰¤ğœ–
(19)
50

--------------------------------------------------------------------------------
[End of Page 63]

Accuracy Parameter ğœ–
The accuracy parameter ğœ–determines how far the output classifier
can be from the optimal one
A Simplified Definition
. . .
ğ¿D, ğ‘“(â„) â‰¤ğœ–
(19)
Approximately Correct
50

--------------------------------------------------------------------------------
[End of Page 64]

Confidence Parameter ğ›¿
The confidence parameter ğ›¿indicates how likely the classifier is to
meet the accuracy requirement
A Simplified Definition
. . . the algorithm returns a hypothesis â„such that, with probability
of at least 1 âˆ’ğ›¿(over the choice of the examples),
ğ¿(D, ğ‘“)(â„) â‰¤ğœ–
(20)
51

--------------------------------------------------------------------------------
[End of Page 65]

Confidence Parameter ğ›¿
The confidence parameter ğ›¿indicates how likely the classifier is to
meet the accuracy requirement
A Simplified Definition
. . . the algorithm returns a hypothesis â„such that, with probability
of at least 1 âˆ’ğ›¿(over the choice of the examples),
ğ¿(D, ğ‘“)(â„) â‰¤ğœ–
(20)
Probably Approximately Correct (PAC)
51

--------------------------------------------------------------------------------
[End of Page 66]

Is It Necessary to Have Both Parameters?
Cen we remove either ğœ–or ğ›¿?
â–¶We need ğ›¿
â–¶Because the training set is randomly generated, which can be
non-representative
52

--------------------------------------------------------------------------------
[End of Page 67]

Is It Necessary to Have Both Parameters?
Cen we remove either ğœ–or ğ›¿?
â–¶We need ğ›¿
â–¶Because the training set is randomly generated, which can be
non-representative
â–¶We need ğœ–
â–¶Because we can only finite number of training examples, even
though the training set is representative
52

--------------------------------------------------------------------------------
[End of Page 68]

PAC Learnability
A hypothesis class His PAC learnable if there exist a function
ğ‘šH(ğœ–, ğ›¿) : (0, 1)2 â†’â„•and a learning algorithm with the following
property:
â–¶for every distribution D over X,
â–¶for every labeling function ğ‘“: X â†’{0, 1}, and
â–¶for every ğœ–, ğ›¿âˆˆ(0, 1),
if the realizable assumption holds wrt H,D,ğ‘“, then when running the
learning algorithm on ğ‘šâ‰¥ğ‘šH(ğœ–, ğ›¿) i.i.d. examples generated by D
and labeled by ğ‘“, the algorithm returns a hypothesis â„such that, with
probability of at least 1 âˆ’ğ›¿,
ğ¿(D, ğ‘“)(â„) â‰¤ğœ–
(21)
53

--------------------------------------------------------------------------------
[End of Page 69]

Sample Complexity
â–¶Sample complexity function: a function of ğœ–and ğ›¿
ğ‘šH(ğœ–, ğ›¿) : (0, 1)2 â†’â„•
(22)
54

--------------------------------------------------------------------------------
[End of Page 70]

Sample Complexity
â–¶Sample complexity function: a function of ğœ–and ğ›¿
ğ‘šH(ğœ–, ğ›¿) : (0, 1)2 â†’â„•
(22)
â–¶How many examples are required to guarantee a probably
approximately correct solution
â–¶many different options
54

--------------------------------------------------------------------------------
[End of Page 71]

Sample Complexity
â–¶Sample complexity function: a function of ğœ–and ğ›¿
ğ‘šH(ğœ–, ğ›¿) : (0, 1)2 â†’â„•
(22)
â–¶How many examples are required to guarantee a probably
approximately correct solution
â–¶many different options
â–¶To be precise, ğ‘šH(ğœ–, ğ›¿) is defined to the minimal function that
satisfies the requirements of PAC learning with ğœ–and ğ›¿
54

--------------------------------------------------------------------------------
[End of Page 72]

Finite Hypothesis Class
Let Hbe a finite hypothesis class. Let ğ›¿âˆˆ(0, 1) and ğœ–> 0 and let ğ‘šbe
an integer that satisfies
ğ‘šâ‰¥log(|H|/ğ›¿)
ğœ–
(23)
Then, for any labeling function ğ‘“, and for any distribution D, for
which the realizability assumption holds, with probability 1 âˆ’ğ›¿over
the choice of an i.i.d. sample ğ‘†of size ğ‘š, we have that for every ERM
hypothesis, â„ğ‘†, it holds that
ğ¿(D, ğ‘“)(â„ğ‘†) â‰¤ğœ–.
(24)
[Shalev-Shwartz and Ben-David, 2014, Corollary 2.3]
55

--------------------------------------------------------------------------------
[End of Page 73]

Example: Finding the Dividing Points
The sample complexity of finite hypothesis space
ğ‘šâ‰¥log(|H|/ğ›¿)
ğœ–
(25)
â–¶The size of the hypothesis space: |H| = 100
â–¶Confidence parameter: ğ›¿= 0.1
â–¶Accuracy parameter: ğœ–= 0.01
ğ‘š0 = log(|H|/ğ›¿)
ğœ–
â‰ˆ691
56

--------------------------------------------------------------------------------
[End of Page 74]

Agnostic PAC Learning

--------------------------------------------------------------------------------
[End of Page 75]

Reconsider the Realizability Assumption
The Realizability Assumption
There exists â„âˆ—âˆˆHsuch that
ğ¿(D, ğ‘“)(â„âˆ—) = â„™ğ‘¥âˆ¼D[â„âˆ—(ğ‘¥) â‰ ğ‘“(ğ‘¥)] = 0
(26)
Comment: this is a strong assumption
â–¶Do we really know ğ‘“?
â–¶Does equation 26 also holds?
58

--------------------------------------------------------------------------------
[End of Page 76]

Example: Unrealistic assumption
Image classification: what is the labeling function of all the images?
14M images, 20K categories
59

--------------------------------------------------------------------------------
[End of Page 77]

Notation Revision
â–¶Remove the labeling function ğ‘“from the framework of PAC
learning
â–¶Modify the definitions
â–¶Revise D as a joint distribution over XÃ— Y
â–¶Revise the true risk of a prediction rule â„to be
ğ¿D(â„) = â„™(ğ‘¥,ğ‘¦)âˆ¼D[â„(ğ‘¥) â‰ ğ‘¦]
(27)
â–¶Revise the empirical risk remains the same
ğ¿ğ‘†(â„) = |{ğ‘–âˆˆ[ğ‘š] : â„(ğ‘¥ğ‘–) â‰ ğ‘¦ğ‘–}|
ğ‘š
(28)
â–¶No fundamental changes, just for the convenience of notations
â–¶One more question that we need to answer: what the best
hypothesis in Hcan do?
60

--------------------------------------------------------------------------------
[End of Page 78]

Agnostic PAC Learnability
A hypothesis class His agnostic PAC learnable if there exist a
function ğ‘šH : (0, 1)2 â†’â„•and a learning algorithm with the
following property:
â–¶for every distribution D over XÃ— {âˆ’1, +1} and
â–¶for every ğœ–, ğ›¿âˆˆ(0, 1),
when running the learning algorithm on ğ‘šâ‰¥ğ‘šH(ğœ–, ğ›¿) i.i.d. examples
generated by D, the algorithm returns a hypothesis â„such that, with
probability of at least 1 âˆ’ğ›¿,
ğ¿D(â„) â‰¤min
â„â€²âˆˆHğ¿D(â„â€²) + ğœ–
(29)
61

--------------------------------------------------------------------------------
[End of Page 79]

Comments
â–¶In general, we have
ğ¿D(â„) â‰¤min
â„â€²âˆˆHğ¿D(â„â€²) + ğœ–
(30)
â–¶If the realizability assumption holds, by the definition we have
min
â„â€²âˆˆHğ¿D(â„â€²) = 0
(31)
and then,
ğ¿D(â„)
â‰¤
min
â„â€²âˆˆHğ¿D(â„â€²) + ğœ–
=
ğœ–
which is a special case of agnostic PAC learning
62

--------------------------------------------------------------------------------
[End of Page 80]

The Bayes Optimal Predictor
If we know the underlying data distribution D, what will be the best
hypothesis in agnostic PAC learning?
63

--------------------------------------------------------------------------------
[End of Page 81]

The Bayes Optimal Predictor
If we know the underlying data distribution D, what will be the best
hypothesis in agnostic PAC learning?
â–¶The Bayes optimal predictor: given a probability distribution D
over XÃ— {âˆ’1, +1}, the predictor is defined as
ğ‘“D(ğ‘¥) =

+1
if â„™[ğ‘¦= 1|ğ‘¥] â‰¥1
2
âˆ’1
otherwise
(32)
63

--------------------------------------------------------------------------------
[End of Page 82]

The Bayes Optimal Predictor
If we know the underlying data distribution D, what will be the best
hypothesis in agnostic PAC learning?
â–¶The Bayes optimal predictor: given a probability distribution D
over XÃ— {âˆ’1, +1}, the predictor is defined as
ğ‘“D(ğ‘¥) =

+1
if â„™[ğ‘¦= 1|ğ‘¥] â‰¥1
2
âˆ’1
otherwise
(32)
â–¶No other predictor can do better: for any predictor â„
ğ¿D(ğ‘“D) â‰¤ğ¿D(â„)
(33)
â–¶Exercise: The Bayes predictor defined in Eq. 32 is optimal
63

--------------------------------------------------------------------------------
[End of Page 83]

Example
Consider the following data distribution
D = 1
2 B(ğ‘¥; 4, 1)
|       {z       }
ğ‘“(ğ‘¥)=+1
+ 1
2 B(ğ‘¥, 1, 4)
|       {z       }
ğ‘“(ğ‘¥)=âˆ’1
(34)
where B(ğ‘¥, ğ›¼, ğ›½) is a Beta distribution with parameters ğ›¼and ğ›½
64

--------------------------------------------------------------------------------
[End of Page 84]

Example
Consider the following data distribution
D = 1
2 B(ğ‘¥; 4, 1)
|       {z       }
ğ‘“(ğ‘¥)=+1
+ 1
2 B(ğ‘¥, 1, 4)
|       {z       }
ğ‘“(ğ‘¥)=âˆ’1
(34)
where B(ğ‘¥, ğ›¼, ğ›½) is a Beta distribution with parameters ğ›¼and ğ›½
The true error of the Bayes predictor is ğ¿D( ğ‘“D) = 0.0625
64

--------------------------------------------------------------------------------
[End of Page 85]

Example (Cont.)
With 2K training examples, we can find â„ğ‘†by minimizing the
empirical risk ğ¿ğ‘†(â„)
â–¶the empirical risk of â„ğ‘†, ğ¿ğ‘†(â„ğ‘†) = 0.0535 (threshold ğ‘= 0.4996)
â–¶the true risk of â„ğ‘†, ğ¿D(â„ğ‘†) = 0.06250018
â–¶Reference: the true error of the Bayes predictor is ğ¿D( ğ‘“D) = 0.0625
65

--------------------------------------------------------------------------------
[End of Page 86]

Reference
Mitchell, T. M. (1997).
Machine learning.
McGraw-Hill.
Shalev-Shwartz, S. and Ben-David, S. (2014).
Understanding machine learning: From theory to algorithms.
Cambridge university press.
66

--------------------------------------------------------------------------------
[End of Page 87]