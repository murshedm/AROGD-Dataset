CS 4774 Machine Learning
Neural Networks
Yangfeng Ji
Information and Language Processing Lab
Department of Computer Science
University of Virginia

--------------------------------------------------------------------------------
[End of Page 1]

Overview
1. From Perceptrons to MLPs
2. From Logistic Regression to Neural Networks
3. Expressive Power of Neural Networks
4. Learning Neural Networks
5. Computation Graph
1

--------------------------------------------------------------------------------
[End of Page 2]

From Perceptrons to MLPs

--------------------------------------------------------------------------------
[End of Page 3]

Perceptrons
â–¶X = â„ğ‘‘
â–¶Y = {âˆ’1, +1}
â–¶Halfspace hypothesis class
Hhalf = {sign(âŸ¨ğ’˜, ğ’™âŸ©) : ğ’˜âˆˆâ„ğ‘‘}
(1)
which is an infinite hypothesis space.
The sign function ğ‘¦= sign(ğ‘¥) is defined as
3

--------------------------------------------------------------------------------
[End of Page 4]

The XOR Problem
ğ‘¦= ğ‘¥1 âŠ•ğ‘¥2
(2)
4

--------------------------------------------------------------------------------
[End of Page 5]

A Multi-Layer Perceptron
The problem can be solved by stacking three perceptrons together, for
example,
The new model is called Multi-Layer Perceptron (MLP).
5

--------------------------------------------------------------------------------
[End of Page 6]

Geometric Interpretation
The previous MLP can be write in the mathematical form as
â„1
=
sign(ğ‘¥1 + ğ‘¥2 âˆ’1.5)
(3)
â„2
=
sign(ğ‘¥1 + ğ‘¥2 âˆ’0.5)
(4)
ğ‘¦
=
sign(âˆ’â„1 + â„2 âˆ’0.5)
(5)
â–¶Each â„ğ‘–defines a classifier by deviding the input space into two
half-spaces
â–¶Equation 3 forms a non-linear classifier by combining two linear
classifiers together
6

--------------------------------------------------------------------------------
[End of Page 7]

What about Learning?
â–¶Although the previous classifier is simple and intuitive, learning
the parameters are not easy, because function sign(Â·) is
non-differentiable!
â–¶Solution: replace sign(Â·) function with the Sigmoid function ğœ(Â·)
â–¶For example, â„1 = ğœ(ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2)
â–¶In other words, transform each perceptron classifier to a logistic
regresion classifier
7

--------------------------------------------------------------------------------
[End of Page 8]

From Logistic Regression to Neu-
ral Networks

--------------------------------------------------------------------------------
[End of Page 9]

Logistic Regression
â–¶An unified form for ğ‘¦âˆˆ{âˆ’1, +1}
ğ‘(ğ‘Œ= +1 | ğ’™) =
1
1 + exp(âˆ’âŸ¨ğ’˜, ğ’™âŸ©)
(6)
â–¶The sigmoid function ğœ(ğ‘) with ğ‘âˆˆâ„
ğœ(ğ‘) =
1
1 + exp(âˆ’ğ‘)
(7)
9

--------------------------------------------------------------------------------
[End of Page 10]

Graphical Representation
â–¶A specific example of LR
ğ‘(ğ‘Œ= 1 | ğ’™) = ğœ(
2
Ã•
ğ‘—=1
ğ‘¤ğ‘—ğ’™Â·,ğ‘—)
(8)
â–¶The graphical representation of this LR model is
ğ‘¥1
ğ‘¥2
Input
layer
ğ‘¦
Output
layer
10

--------------------------------------------------------------------------------
[End of Page 11]

From LR to Neural Networks
Build upon logistic regression, a simple neural network can be
constructed as
ğ‘§ğ‘˜
=
ğœ(
ğ‘‘
Ã•
ğ‘—=1
ğ‘¤(1)
ğ‘˜,ğ‘—ğ‘¥Â·,ğ‘—)
ğ‘˜âˆˆ[ğ¾]
(9)
ğ‘ƒ(ğ‘¦= 1 | ğ’™)
=
ğœ(
ğ¾
Ã•
ğ‘˜=1
ğ‘¤(ğ‘œ)
ğ‘˜ğ‘§ğ‘˜)
(10)
â–¶ğ’™âˆˆâ„ğ‘‘: ğ‘‘-dimensional input
â–¶ğ‘¦âˆˆ{âˆ’1, +1} (binary classification problem)
â–¶{ğ‘¤(1)
ğ‘˜,ğ‘–} and {ğ‘¤(ğ‘œ)
ğ‘˜} are two sets of the parameters, and
â–¶ğ¾is the number of hidden units, each of them has the same form
as a LR.
11

--------------------------------------------------------------------------------
[End of Page 12]

Mathematical Formulation
â–¶Element-wise formulation
ğ‘§ğ‘˜
=
ğœ(
ğ‘‘
Ã•
ğ‘—=1
ğ‘¤(1)
ğ‘˜,ğ‘—ğ‘¥Â·,ğ‘—)
ğ‘˜âˆˆ[ğ¾]
(11)
ğ‘ƒ(ğ‘¦= +1 | ğ’™)
=
ğœ(
ğ¾
Ã•
ğ‘˜=1
ğ‘¤(ğ‘œ)
ğ‘˜ğ‘§ğ‘˜)
(12)
â–¶Matrix-vector formulation
ğ’›
=
ğœ(W(1)ğ’™)
(13)
ğ‘ƒ(ğ‘¦= +1 | ğ’™)
=
ğœ((ğ’˜(ğ‘œ))Tğ’›)
(14)
where W(1) âˆˆâ„ğ¾Ã—ğ‘‘and w(ğ‘œ) âˆˆâ„ğ¾
12

--------------------------------------------------------------------------------
[End of Page 13]

Graphical Representation
ğ‘¥Â·,1
ğ‘¥Â·,2
Input
layer
ğ‘§1
ğ‘§2
ğ‘§3
Hidden
layer
ğ‘¦
Output
layer
â–¶Depth: 2 (two-layer neural network)
â–¶Width: 3 (the maximal number of units in each layer)
Demo for solve the XOR problem
13

--------------------------------------------------------------------------------
[End of Page 14]

Hypothesis Space
The hypothesis space of neural networks is usually defined by the
architecture of the network, which includes
â–¶the nodes in the network,
â–¶the connections in the network, and
â–¶the activation function (e.g., ğœ, tanh)
ğ‘¥Â·,1
ğ‘¥Â·,2
Input
layer
ğ‘§1
ğ‘§2
ğ‘§3
Hidden
layer
ğ‘¦
Output
layer
14

--------------------------------------------------------------------------------
[End of Page 15]

Other Activation Functions
(a) Sign function
(b) Tanh function
(c)
ReLU
function
[Jarrett et al., 2009]
15

--------------------------------------------------------------------------------
[End of Page 16]

Expressive Power of Neural Net-
works

--------------------------------------------------------------------------------
[End of Page 17]

Two-layer NNs with Sign Function
Consider a neural network defined by the following functions
ğ‘§ğ‘˜
=
sign(
ğ‘‘
Ã•
ğ‘—=1
ğ‘¤(1)
ğ‘˜,ğ‘—ğ‘¥Â·,ğ‘—)
ğ‘˜âˆˆ[ğ¾]
(15)
â„(ğ’™)
=
sign(
ğ¾
Ã•
ğ‘˜=1
ğ‘¤(ğ‘œ)
ğ‘˜ğ‘§ğ‘˜)
(16)
where sign(ğ‘) is the sign function.
â„(ğ’™) can be rewritten as
â„(ğ’™) = sign Â©Â­
Â«
ğ¾
Ã•
ğ‘˜=1
ğ‘¤(ğ‘œ)
ğ‘˜
Â· sign(
ğ‘‘
Ã•
ğ‘—=1
ğ‘¤(1)
ğ‘˜,ğ‘–ğ‘¥Â·,ğ‘—)ÂªÂ®
Â¬
(17)
17

--------------------------------------------------------------------------------
[End of Page 18]

Decision Boundary
â„(ğ’™) is defined by a combination of ğ¾linear predictors
ğ‘¥1
ğ‘¥2
Similar conclusion applies to other activation functions. [Demo]
[Shalev-Shwartz and Ben-David, 2014, Page 274]
18

--------------------------------------------------------------------------------
[End of Page 19]

Universal Approximation Theorem
Restrict the inputs ğ‘¥Â·,ğ‘—âˆˆ{âˆ’1, +1}âˆ€ğ‘—âˆˆ[ğ‘‘] as binary
Universal Approximation Theorem
For every ğ‘‘, there exists a two-layer neural network (Equations 15 â€“
16), such that this hypothesis space contains all functions from
{âˆ’1, +1}ğ‘‘to {âˆ’1, +1}
â–¶The minimal size of network that satisfies the theorem is
exponential in ğ‘‘
â–¶Similar results hold for ğœas the activation function
[Shalev-Shwartz and Ben-David, 2014, Section 20.3]
19

--------------------------------------------------------------------------------
[End of Page 20]

Learning Neural Networks

--------------------------------------------------------------------------------
[End of Page 21]

Neural Network Predictions
Consider a binary classification problem with Y = {âˆ’1, +1},
â–¶A two-layer neural network gives the following prediction as
ğ‘ƒ(ğ‘Œ= +1 | ğ’™) = ğœ

(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)

(18)
where {ğ’˜(ğ‘œ), W(1)} are the parameters
â–¶Assume the ground-truth label is ğ‘¦, letâ€™s introduce an empirical
distribution
ğ‘(ğ‘Œ= ğ‘¦â€² | ğ’™) = ğ›¿(ğ‘¦â€², ğ‘¦) =

1
ğ‘¦â€² = ğ‘¦
0
ğ‘¦â€² â‰ ğ‘¦
(19)
21

--------------------------------------------------------------------------------
[End of Page 22]

Cross Entropy
Given one data point, The loss function of a neural network is usually
defined as the cross entropy of the prediction distribution ğ‘and the
empirical distribution ğ‘
ğ»(ğ‘, ğ‘)
=
âˆ’ğ‘(ğ‘Œ= +1 | ğ’™) log ğ‘(ğ‘Œ= +1 | ğ’™)
âˆ’ğ‘(ğ‘Œ= âˆ’1 | ğ’™) log ğ‘(ğ‘Œ= âˆ’1 | ğ’™)
(20)
Since ğ‘is defined with a Delta function, Depending on ğ‘¦, we have
ğ»(ğ‘, ğ‘) =

âˆ’log ğ‘(ğ‘Œ= +1 | ğ’™)
ğ‘Œ= +1
âˆ’log ğ‘(ğ‘Œ= âˆ’1 | ğ’™)
ğ‘Œ= âˆ’1
(21)
It is equivalent to the negative log-likelihood (NLL) function used in
learning LR.
22

--------------------------------------------------------------------------------
[End of Page 23]

ERM
â–¶Given a set of training example ğ‘†= {(ğ’™ğ‘–, ğ‘¦ğ‘–)}ğ‘š
ğ‘–=1, the loss function
is defined as
ğ¿(ğœ½) = âˆ’
ğ‘š
Ã•
ğ‘–=1
log ğ‘(ğ‘¦ğ‘–| ğ’™ğ‘–)
(22)
where ğœ½indicates all the parameters in a network.
â–¶For example, ğœ½= {ğ’˜(ğ‘œ), W(1)}, for the previously defined
two-layer neural network
â–¶Just like learning a LR, we can use gradient-based learning
algorithm
23

--------------------------------------------------------------------------------
[End of Page 24]

Gradient-based Learning
A simple scratch of gradient-based learning1
1. Compute the gradient of ğœ½, ğœ•ğ¿(ğœ½)
ğœ•ğœ½
2. Update the parameter with the gradient
ğœ½(new) â†ğœ½(old) âˆ’ğœ‚Â· ğœ•ğ¿(ğœ½)
ğœ•ğœ½

ğœ½=ğœ½(old)
(23)
where ğœ‚is the learning rate
3. Go back step 1 until it converges
1More detail will be discussed in the next lecture
24

--------------------------------------------------------------------------------
[End of Page 25]

Gradient Computation
Consider the two-layer neural network with one training example
(ğ’™, ğ‘¦), to further simplify the computation, we assume ğ‘¦= +1
log ğ‘(ğ‘¦| ğ’™) = log ğœ

(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)

(24)
The gradient with respect to ğ’˜(ğ‘œ) is
ğœ•ğ¿(ğœ½)
ğœ•ğ’˜(ğ‘œ)
=
âˆ’
ğœ•log ğœ

Â·

ğœ•ğœ

Â·

Â·
ğœ•ğœ

(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)

ğœ•(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)
Â· ğœ•(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)
ğœ•ğ’˜(ğ‘œ)
=
âˆ’
n
1 âˆ’ğœ

(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)
 o
Â· ğœ(W(1)ğ’™)
(25)
which is in the similar form as the LR updating equation.
25

--------------------------------------------------------------------------------
[End of Page 26]

Gradient Computation (II)
The gradient with respect to ğ‘Š(1) is
ğœ•ğ¿(ğœ½)
ğœ•W(1)
=
âˆ’
ğœ•log ğœ

Â·

ğœ•ğœ

Â·

Â·
ğœ•ğœ

(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)

ğœ•(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)
Â·ğœ•(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)
ğœ•ğœ(W(1)ğ’™)
Â· ğœ•ğœ(W(1)ğ’™)
ğœ•W(1)ğ’™
Â· ğœ•W(1)ğ’™
ğœ•W(1)
(26)
â–¶Both of them are the applications of the chain rule in calculus
plus some derivatives of basic functions
â–¶In the literature of neural networks, it is called the
back-propagation algorithm [Rumelhart et al., 1986]
26

--------------------------------------------------------------------------------
[End of Page 27]

Computation Graph

--------------------------------------------------------------------------------
[End of Page 28]

Forward Operations
Consider the example of a two-layer neural network
ğ‘ƒ(ğ‘Œ= +1 | ğ’™) = ğœ

(ğ’˜(ğ‘œ))Tğœ(W(1)ğ’™)

(27)
A neural network is a composition of some basic functions and
operations. For example
â–¶ğœ(Â·)
â–¶matrix transpose (ğ’˜(ğ‘œ))T
â–¶matrix-vector multiplication W(1)ğ’™
28

--------------------------------------------------------------------------------
[End of Page 29]

Forward Graph
The computation graph of the two-layer neural network2
ğ’™
W(1) Â· ğ’™
W(1)
ğœ
(ğ’˜(ğ‘œ))Tğ’›
ğ’˜(ğ‘œ)
ğœ
ğ‘(ğ‘Œ| ğ’™)
2For simplicity, the transpose operation is ignored from the graph
29

--------------------------------------------------------------------------------
[End of Page 30]

Backward Operations
Similarly, the gradient of neural network parameters are computed
with a series of backward operations associated with the derivative of
some basic function. For example
â–¶
ğœ•ğœ(ğ‘¥)
ğœ•ğ‘¥
= ğœ(ğ‘¥)(1 âˆ’ğœ(ğ‘¥))
â–¶
ğœ•ğ’‚Tğ’™
ğœ•ğ’™
= ğ’‚
â–¶
ğœ•log(ğ‘¥)
ğœ•ğ‘¥
= 1
ğ‘¥
â–¶
ğœ•Wğ’™
ğœ•ğ’™=
ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°
ğ’™T
...
ğ’™T
ï£¹ï£ºï£ºï£ºï£ºï£ºï£»
30

--------------------------------------------------------------------------------
[End of Page 31]

Backward Graph
With the chain rule, gradient of the loss function with respect to any
parameter can be computed backward step-by-step along the path
ğ’™
W(1) Â· ğ’™
W(1)
ğœ
(ğ’˜(ğ‘œ))Tğ’›
ğ’˜(ğ‘œ)
ğœ
âˆ’log ğ‘(ğ‘Œ| ğ’™)
ğœ•(W(1) Â· ğ’™)
ğœ•ğœ
ğœ•((ğ’˜(ğ‘œ))Tğ’›)
ğœ•ğœ
ğœ•W(1)
ğœ•ğ’˜(ğ‘œ)
31

--------------------------------------------------------------------------------
[End of Page 32]

Basic Operators
Every basic operator need to be re-implemented, so it can be attached
to the computation graph, and also have the forward/backward
functions. For example
32

--------------------------------------------------------------------------------
[End of Page 33]

Computation Graph
Perform the forward/backward step with a graph of basic operations
(e.g., PyTorch, Tensorflow)
ğ’™
W(1) Â· ğ’™
W(1)
ğœ
(ğ’˜(ğ‘œ))Tğ’›
ğ’˜(ğ‘œ)
ğœ
ğ‘(ğ‘Œ| ğ’™)
ğ’™
W(1) Â· ğ’™
W(1)
ğœ
(ğ’˜(ğ‘œ))Tğ’›
ğ’˜(ğ‘œ)
ğœ
âˆ’log ğ‘(ğ‘Œ| ğ’™)
ğœ•(W(1) Â· ğ’™)
ğœ•ğœ
ğœ•((ğ’˜(ğ‘œ))Tğ’›)
ğœ•ğœ
ğœ•W(1)
ğœ•ğ’˜(ğ‘œ)
â–¶Modular implementation: implement each module with its
forward/backward operations together
â–¶Automatic differentiation: automatically run with the backward
step
33

--------------------------------------------------------------------------------
[End of Page 34]

Another Computation Graph
Link
34

--------------------------------------------------------------------------------
[End of Page 35]

Reference
Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2009).
What is the best multi-stage architecture for object recognition?
In Proceedings of the 12th International Conference on Computer Vision, pages 2146â€“2153. IEEE.
LeCun, Y. (2020).
Self-supervised learning.
Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986).
Learning representations by back-propagating errors.
Nature, 323(6088):533â€“536.
Shalev-Shwartz, S. and Ben-David, S. (2014).
Understanding machine learning: From theory to algorithms.
Cambridge university press.
35

--------------------------------------------------------------------------------
[End of Page 36]